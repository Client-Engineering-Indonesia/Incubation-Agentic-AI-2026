# Lab 2.4: Create Python Tool and Agent using ADK

In this lab, you will learn how to create custom Python tools and agents using the watsonx Orchestrate Agent Development Kit (ADK). You'll work with a complete example that demonstrates SQL query execution and data analysis capabilities.

## Overview

This lab includes:
- **Custom Python Tool**: A SQL execution tool that safely runs SELECT queries on PostgreSQL
- **Two Intelligent Agents**: 
  - SQL Translator Agent: Converts natural language to SQL
  - Data Analyst Agent: Performs comprehensive data analysis

## Prerequisites

Before starting, ensure you have:
- Completed Lab 2.1 (Creating connection)
- Completed Lab 2.2 (Install ADK)
- Completed Lab 2.3 (Create local environment)
- PostgreSQL connection configured in watsonx Orchestrate

---

## Step 1: Download Assets

First, download all the required files from the `assets/` directory. The structure should be maintained as follows:

```
assets/
â”œâ”€â”€ .env                           # Environment variables
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ execute_sql_stmt.py       # SQL execution tool
â”‚   â””â”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ agents/
    â”œâ”€â”€ sql_translator_agent.yaml # SQL translation agent
    â””â”€â”€ data_analyst_agent.yaml   # Data analysis agent
```

### Download Commands

```bash
# Navigate to your lab directory
cd "Incubation-Agentic-AI-2026/Lab 4-Develop using Agent Development Kit (ADK)"

# Verify assets directory exists
ls -la assets/
```

---

## Step 2: Review the Files

### ðŸ“„ **File 1: `assets/tools/execute_sql_stmt.py`**

This is a custom Python tool that executes SQL SELECT statements on a PostgreSQL database.

#### **Key Features:**

1. **Security First**: Only allows SELECT queries, blocks dangerous operations (DROP, DELETE, INSERT, UPDATE, etc.)
2. **Connection Management**: Uses watsonx Orchestrate connection credentials
3. **Error Handling**: Comprehensive error handling with detailed error messages
4. **JSON-Safe Output**: Returns results in a structured, JSON-compatible format

#### **Code Structure:**

```python
@tool(
    name="execute_sql_statement",
    description="Execute a SQL SELECT statement on PostgreSQL database and return results.",
    permission=ToolPermission.ADMIN,
    expected_credentials=[
        {"app_id": MY_APP_ID, "type": ConnectionType.KEY_VALUE}
    ],
)
def execute_sql_statement(sql_statement: str) -> Dict[str, Any]:
    # Security validation
    # Database connection
    # Query execution
    # Result formatting
```

#### **How It Works:**

1. **Input**: Receives a SQL SELECT statement as a string
2. **Validation**: Checks if the query is safe (SELECT only, no dangerous keywords)
3. **Execution**: Connects to PostgreSQL using credentials from watsonx Orchestrate
4. **Output**: Returns a dictionary with:
   - `status`: "success" or "error"
   - `sql_statement`: The executed SQL
   - `count`: Number of rows returned
   - `results`: Array of result rows as dictionaries
   - `message`: Descriptive message

#### **Example Output:**

```json
{
  "status": "success",
  "sql_statement": "SELECT * FROM coffee_sales LIMIT 5",
  "count": 5,
  "results": [
    {
      "datetime": "2024-03-01 10:15:50.520",
      "payment_type": "card",
      "card": "ANON-0000-0000-0001",
      "money": 38.7,
      "coffee_name": "Latte"
    },
    ...
  ],
  "message": "Query executed successfully. Returned 5 rows."
}
```

---

### ðŸ“„ **File 2: `assets/tools/requirements.txt`**

This file lists all Python dependencies required for the tool.

#### **Dependencies:**

- **psycopg2-binary**: PostgreSQL database adapter for Python
- **python-dotenv**: Environment variable management
- **ibm-watsonx-orchestrate-adk**: The ADK SDK itself
- **requests**: HTTP library for API calls
- **pyyaml**: YAML file parsing

These dependencies will be automatically installed when you import the tool.

---

### ðŸ“„ **File 3: `assets/agents/sql_translator_agent.yaml`**

This agent translates natural language questions into PostgreSQL-compatible SQL queries.

#### **Agent Configuration:**

```yaml
spec_version: v1
name: sql_translator_agent
display_name: SQL Translator Agent
llm: groq/openai/gpt-oss-120b
style: react
```

#### **Key Capabilities:**

1. **Natural Language Understanding**: Interprets user questions about coffee sales data
2. **SQL Generation**: Creates valid PostgreSQL SELECT queries
3. **Schema Awareness**: Knows the structure of the `coffee_sales` table
4. **Output Format**: Returns ONLY the SQL statement (no explanations)

#### **Database Schema Knowledge:**

The agent understands this table structure:

```sql
Table: coffee_sales
Columns:
  - datetime (timestamp): Transaction date and time
  - payment_type (text): Payment method ('card' or 'cash')
  - card (text): Anonymized card number
  - money (numeric): Transaction amount
  - coffee_name (text): Product name (Latte, Americano, Hot Chocolate, etc.)
```

#### **Example Translations:**

| User Question | Generated SQL |
|--------------|---------------|
| "What are the total sales for each coffee type?" | `SELECT coffee_name, COUNT(*) as transaction_count, SUM(money) as total_sales FROM coffee_sales GROUP BY coffee_name ORDER BY total_sales DESC;` |
| "Show me sales from March 2024" | `SELECT datetime, coffee_name, money FROM coffee_sales WHERE datetime >= '2024-03-01' AND datetime < '2024-04-01' ORDER BY datetime;` |
| "What's the average transaction amount?" | `SELECT ROUND(AVG(money), 2) as average_transaction FROM coffee_sales;` |

#### **Conversation Starters:**

The agent provides helpful starting prompts:
- "What are the total sales for this month?"
- "Show me the top 5 best-selling coffee products"
- "What's the average transaction amount?"
- "How many transactions were made with cards vs cash?"
- "Show me daily sales trends for the last week"

---

### ðŸ“„ **File 4: `assets/agents/data_analyst_agent.yaml`**

This is the main orchestrator agent that performs comprehensive data analysis.

#### **Agent Configuration:**

```yaml
spec_version: v1
name: data_analyst_agent
display_name: Data Analyst Agent
llm: groq/openai/gpt-oss-120b
style: react

collaborators:
  - sql_translator_agent

tools:
  - execute_sql_statement
```

#### **Workflow:**

The agent follows a structured 5-step process:

1. **Understand the Question**: Analyzes what the user wants to know
2. **Translate to SQL**: Uses the `sql_translator_agent` collaborator to convert the question into SQL
3. **Execute Query**: Uses the `execute_sql_statement` tool to run the SQL and retrieve data
4. **Analyze Results**: Examines the data for patterns, trends, and insights
5. **Generate Report**: Creates a comprehensive analysis report

#### **Report Structure:**

Each analysis includes:

**Executive Summary** (2-3 sentences)
- High-level overview of findings
- Most important insight

**Key Findings** (Bullet points)
- Top 3-5 most significant discoveries
- Specific numbers and percentages

**Detailed Analysis**
- Data breakdown by relevant dimensions
- Explanation of what the numbers mean
- Context and comparisons

**Trends and Patterns**
- Temporal patterns (daily, weekly, monthly)
- Product preferences
- Payment behavior

**Recommendations** (Actionable items)
- Business strategies based on data
- Areas for improvement
- Opportunities to capitalize on

#### **Example Analysis:**

When asked "What are our best-selling products?", the agent will:

1. Ask sql_translator_agent to generate SQL
2. Execute the query using execute_sql_statement
3. Analyze the results
4. Generate a comprehensive report like:

```
Coffee Sales Analysis Report

Executive Summary:
Based on the sales data analysis, Latte emerges as the top-performing product 
with 1,234 transactions generating $47,829.80 in revenue, representing 42% of 
total sales. This indicates strong customer preference for premium coffee beverages.

Key Findings:
- Latte leads with $47,829.80 (42% of total revenue)
- Hot Chocolate ranks second at $33,127.20 (29% of revenue)
- Americano generates $28,515.30 (25% of revenue)
- Average transaction value: $36.45
- Total transactions analyzed: 3,077

[... detailed analysis continues ...]

Recommendations:
1. Promote Latte: Increase marketing for top performer
2. Bundle Strategy: Create Latte + Hot Chocolate combo deals
3. Americano Upsell: Train staff to suggest size upgrades
4. Pricing Analysis: Consider slight Americano price increase
5. Inventory Management: Ensure adequate Latte supplies during peak hours
```

---

## Step 3: Review the Files (Take Your Time!)

**â° IMPORTANT: Please take your time to review all the files carefully.**

Before proceeding to import, make sure you understand:

1. **Tool Functionality**: How `execute_sql_stmt.py` works
   - Security measures
   - Connection handling
   - Error management
   - Output format

2. **SQL Translator Agent**: How it converts natural language to SQL
   - Schema knowledge
   - SQL generation patterns
   - Output format (SQL only)

3. **Data Analyst Agent**: How it orchestrates the workflow
   - Collaboration with SQL Translator
   - Tool usage
   - Report generation
   - Analysis structure

4. **Dependencies**: What libraries are needed and why

**Questions to Consider:**
- How does the tool ensure security?
- What happens if someone tries to run a DELETE query?
- How do the two agents work together?
- What kind of insights can the Data Analyst Agent provide?

---

## Step 4: Import the Tool

Once you've reviewed the files, import the SQL execution tool:

```bash
orchestrate tools import \
  -k python \
  -f assets/tools/execute_sql_stmt.py \
  -a postgres-connection \
  -r assets/tools/requirements.txt
```

### Command Breakdown:

- `-k python`: Specifies the tool kind (Python)
- `-f assets/tools/execute_sql_stmt.py`: Path to the tool file
- `-a postgres-connection`: App ID for the connection (must match your connection name from Lab 2.1)
- `-r assets/tools/requirements.txt`: Path to requirements file

### Verification:

Check that the tool was imported:

```bash
orchestrate tools list
```

You should see `execute_sql_statement` in the list.

---

## Step 5: Import the SQL Translator Agent

Import the first agent that translates natural language to SQL:

```bash
orchestrate agents import -f assets/agents/sql_translator_agent.yaml
```

### Verification:

```bash
orchestrate agents list
```

You should see `sql_translator_agent` in the list.

---

## Step 6: Import the Data Analyst Agent

Import the main orchestrator agent:

```bash
orchestrate agents import -f assets/agents/data_analyst_agent.yaml
```

### Verification:

```bash
orchestrate agents list
```

You should see both agents:
- `sql_translator_agent`
- `data_analyst_agent`

---

## Step 7: Test the Agents

### Test SQL Translator Agent

1. Go to watsonx Orchestrate web interface
2. Navigate to **Agents** section
3. Select **sql_translator_agent**
4. Try these test queries:

```
"What are the total sales by product?"
"Show sales from March 2024"
```

![Test SQL Translator Agent](images/2.4-test-sql-translator-agent.png)

### Test Data Analyst Agent

1. Select **data_analyst_agent**
2. Try these analysis requests:

```
"Show me the top 5 best-selling coffee products"
```

![Test Data Analyst Agent](images/2.4-test-data-analyst-agent.png)

3. You can also experiment with other queries

```
"What are our best-selling products?"
"Analyze payment methods used by customers"
"What's our average transaction value and how does it vary by product?"
```

---

## Understanding the Architecture

### Component Interaction Flow

```
User Question
     â†“
Data Analyst Agent (Orchestrator)
     â†“
     â”œâ”€â†’ SQL Translator Agent (Collaborator)
     â”‚        â†“
     â”‚   Generates SQL Query
     â”‚        â†“
     â””â”€â†’ Execute SQL Statement Tool
              â†“
         PostgreSQL Database
              â†“
         Returns Results
              â†“
    Data Analyst Agent
              â†“
    Analyzes & Generates Report
              â†“
         User Receives Insights
```

### Key Concepts

1. **Tool**: A reusable function that performs a specific task (e.g., execute SQL)
2. **Agent**: An intelligent entity that can use tools and collaborate with other agents
3. **Collaborator**: An agent that another agent can call upon for specialized tasks
4. **Orchestration**: The coordination of multiple agents and tools to accomplish complex tasks

---

## Additional Resources

- [watsonx Orchestrate ADK Documentation](https://www.ibm.com/docs/en/watsonx/orchestrate)
- [Python Tool Development Guide](https://github.com/ibm-watsonx-orchestrate-adk)
- [Agent Configuration Reference](https://www.ibm.com/docs/en/watsonx/orchestrate/agents)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)

---

**Congratulations! You've completed Lab 2.4!** ðŸŽ‰

You're now ready to build sophisticated agentic AI applications using watsonx Orchestrate ADK.